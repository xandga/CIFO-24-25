{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from library.solution import Solution\n",
    "from library.problems.tsp import TSPSolution\n",
    "from library.problems.ks import KSSolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing\n",
    "\n",
    "Simulated Annealing is an optimization algorithm that explores solutions by allowing both improvements and occasional worse moves to escape local optima. The probability of accepting worse solutions decreases over time, controlled by a temperature parameter that gradually cools. This balance between exploration and exploitation helps the algorithm find a global optimum rather than getting stuck in suboptimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-code\n",
    "\n",
    "1. Define the current solution (usually at random)\n",
    "2. Repeat until termination condition (usually nr of iterations):\n",
    "    1. Repeat **L** times:\n",
    "        1. Choose a random neighbor of the current solution\n",
    "        2. If random neighbor is better than current solution, replace current solution by neighbor. Otherwise, accept the nieghbor as the current solution with probability: $$exp(-\\frac{neighbor.fitness - current.fitness}{C})$$\n",
    "    2. Decrement **C** by dividing it by **H**\n",
    "3. Return current solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Implementation\n",
    "\n",
    "Let's implement the simmulated annealing algorithm using python. The function that implements the algorithm should receive the following arguments:\n",
    "- `initial_solution`: Initial current solution\n",
    "- `C`: Control parameter\n",
    "- `L`: Number of iterations with same C\n",
    "- `H`: Decreasing rate of parameter C\n",
    "- `maximization`: boolean that indicates if we're solving a maximization or minimization problem\n",
    "- `max_iter`: maximum number of interations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement simulated annealing algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we assume that a solution has the following methods:\n",
    "- `fitness()`\n",
    "- `get_random_neighbor()`\n",
    "\n",
    "Additionally, `get_random_neighbor()` must return a solution that also implements these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving TSP with Simulated Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve TSP with simulated annealing we need to define a `TSPSASolution` class that inherits from `TSPSolution` and implements the `get_random_neighbor()` method.\n",
    "\n",
    "In the previous notebook, we implemented `TSPSolution`, which provides the `fitness()` and `random_initial_value()` methods. We also created `TSPHillClimbingSolution`, which extends `TSPSolution` and implements `get_neighbors()`.\n",
    "\n",
    "Simulated Annealing requires selecting only random neighbor rather than generating all neighbors. Therefore, we can create a new class `TSPSASolution`, that implements the method that is required for simulated annealing to work: `get_random_neighbor()`.\n",
    "\n",
    "We could do this two ways:\n",
    "- Inherit from `TSPHillClimbingSolution` and use the `get_neighbors()` method inside the `get_random_neighbor()` method to first get all neighbors, and then radomly select one\n",
    "- Inherit from `TSPSolution` and implement only the `get_random_neighbor()`\n",
    "\n",
    "Let's go with the second one to keep the code as independent, eficient and modular as possible.\n",
    "\n",
    "![TSP Solutions](images/tsp-solutions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neighbor of a TSP solution can be obtained by swapping two consecutive cities on the route (excluding the starting and end points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement TSPSASolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = TSPSASolution()\n",
    "\n",
    "print('Solution', solution)\n",
    "print('Random neighbor', solution.get_random_neighbor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can apply the simulated annealing algorithm by giving it an random initial solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply simulated annealing to TSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of `TSPSASolution` can be found in `library/problems/tsp.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving KS with Simulated Annealing\n",
    "\n",
    "To solve Knapsack with simulated annealing we need to define a `KSSASolution` class that inherits from `KSSolution` and implements the `get_random_neighbor()` method.\n",
    "\n",
    "In the previous notebook, we implemented `KSSolution`, which provides the `fitness()` and `random_initial_value()` methods. We also created `KSHillClimbingSolution`, which extends `KSSolution` and implements `get_neighbors()`.\n",
    "\n",
    "Since Simulated Annealing requires selecting a random neighbor rather than generating all neighbors, we can create a new class, `KSSASolution`, that implements the `get_random_neighbor()` method.\n",
    "\n",
    "Similarly to what we just did for TSP, let's implement the `KSSASolution` that inherits from `TSPSolution` and implements the `get_random_neighbor()`.\n",
    "\n",
    "A neighbor of a KS solution can be obtained by randomly flipping a bit, meaning, adding or removing an item from the knapsack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement KSSASolution (short for KnapSack Simulated Annealing Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = KSSASolution()\n",
    "\n",
    "print('Solution', solution)\n",
    "print('Random neighbor', solution.get_random_neighbor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can apply the simulated annealing algorithm by giving it an random initial solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply simulated annealing to Knapsack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
